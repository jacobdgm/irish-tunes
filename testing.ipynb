{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust these constants, then run entire notebook.\n",
    "\n",
    "path_to_model = \"./2021-07-23.3/results/checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parameters = {\n",
    "        'max_length': 128,\n",
    "        'temperature': 0.9,\n",
    "        'no_repeat_ngram_size': 4,\n",
    "        'do_sample': True,\n",
    "        'top_k': 50}\n",
    "\n",
    "two_prompts= [\"\"\"R: reel\n",
    "M: 4/4\n",
    "K: Edor\n",
    "|: E2 B E d E B E |\"\"\",\n",
    "             \n",
    "      \"\"\"R: jig\n",
    "M: 6/8\n",
    "K: Gmaj\n",
    "|: G3 G A B |\"\"\"]\n",
    "\n",
    "\n",
    "test_prompts = [\n",
    "    \n",
    "    # drowsy maggie - Reel, Edor\n",
    "    \"\"\"R: reel\n",
    "M: 4/4\n",
    "K: Edor\n",
    "|: E2 B E d E B E |\"\"\",\n",
    "    \n",
    "    # kesh jig - Jig, Gmaj\n",
    "    \"\"\"R: jig\n",
    "M: 6/8\n",
    "K: Gmaj\n",
    "|: G3 G A B |\"\"\",\n",
    "    \n",
    "    # john ryan's - Polka, Dmaj \n",
    "    \"\"\"R: polka\n",
    "M: 2/4\n",
    "K: Dmaj\n",
    "d d B/ c/ d/ B/ |\"\"\",\n",
    "    \n",
    "    # king of the fairies - Hornpipe\n",
    "    \"\"\"R: hornpipe\n",
    "M: 4/4\n",
    "K: Edor\n",
    "|: B,2 | E D E F G F G A\"\"\",\n",
    "    \n",
    "    # inisheer - Waltz\n",
    "    \"\"\"R: waltz\n",
    "M: 3/4\n",
    "K: Gmaj\n",
    "B2 B A B d |\"\"\",\n",
    "    \n",
    "    # the butterfly - Slip Jig\n",
    "    \"\"\"R: slip jig\n",
    "M: 9/8\n",
    "K: Emin\n",
    "|: B2 E G2 E F3 |\"\"\",\n",
    "    \n",
    "    # banish misfortune - Dmix\n",
    "    \"\"\"R: jig\n",
    "M: 6/8\n",
    "K: Dmix\n",
    "f e d c A G |\"\"\",\n",
    "    \n",
    "    # tam lin - Dmin, low register\n",
    "    \"\"\"R: reel\n",
    "M: 4/4\n",
    "K: Dmin\n",
    "A,2 D A, F A, D A, |\"\"\",\n",
    "    \n",
    "    # cliffs of moher - Ador, high register\n",
    "    \"\"\"R: jig\n",
    "M: 6/8\n",
    "K: Adow\n",
    "|: a3 b a g |\"\"\",\n",
    "    \n",
    "    # silver spear - no closing barline\n",
    "    \"\"\"R: reel\n",
    "M: 4/4\n",
    "K: Dmaj\n",
    "A |: F A (3 A A A B A F A\"\"\",\n",
    "    \n",
    "    # unspecified tune types and meters\n",
    "    \"R: jig\",\n",
    "    \"R: reel\",\n",
    "    \"R: polka\",\n",
    "    \"R: waltz\",\n",
    "    \"R: hornpipe\",\n",
    "    \"R: slip jig\",\n",
    "    \"M: 4/4\",\n",
    "    \"M: 6/8\",\n",
    "    \"M: 3/4\",\n",
    "    \"M: 2/4\",\n",
    "    \"M: 9/8\",\n",
    "    \n",
    "    # single notes\n",
    "    \"G\",\n",
    "    \"e\"\n",
    "]\n",
    "\n",
    "\n",
    "# for compiling html file\n",
    "html_header = \"\"\"<html>\n",
    "<meta charset=\"UTF-8\"/>\n",
    "<script src=\"http://moinejf.free.fr/js/abcweb-1.js\"></script>\n",
    "<script src=\"http://moinejf.free.fr/js/snd-1.js\"></script>\n",
    "<style>svg {display:block}</style>\n",
    "<title></title>\n",
    "</head>\n",
    "<body bgcolor=\"#faf0e6\">\"\"\"\n",
    "\n",
    "html_footer = \"\"\"</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "html_abc_prefix = \"\"\"<script type=\"text/vnd.abc\">\n",
    "%abc-2.2\n",
    "%%pagewidth 14cm\n",
    "%%bgcolor white\n",
    "%%topspace 0\n",
    "%%composerspace 0\n",
    "%%leftmargin 0.8cm\n",
    "%%rightmargin 0.8cm\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "html_abc_postfix = \"\"\"</script>\\n\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path_to_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(start_text = \"a\", number = 6, parameters = test_parameters):\n",
    "    # encoding the input text\n",
    "    input_ids = tokenizer.encode(start_text, return_tensors='pt')\n",
    "    output = model.generate(input_ids, num_return_sequences = number, **parameters)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_suite(path = path_to_model,\n",
    "               parameters = test_parameters,\n",
    "               prompts = test_prompts,\n",
    "               adjust_tabs = True):\n",
    "    \n",
    "    current_time = time.strftime(\"%Y-%m-%dt%H:%M:%S\", time.localtime())\n",
    "    txt_file_name = \"test_results/{t}.txt\".format(t = current_time)\n",
    "    html_file_name = \"test_results/{t}.html\".format(t = current_time)\n",
    "    print(\"running tests on model at {}\".format(path))\n",
    "    print(\"saving to {} and {}\".format(txt_file_name, html_file_name))\n",
    "    \n",
    "    with open(txt_file_name, 'a') as txt_file, open(html_file_name, 'a') as html_file:\n",
    "        \n",
    "        html_file.write(html_header)\n",
    "        \n",
    "        txt_file.write('{}\\n\\n'.format(current_time))\n",
    "        html_file.write('<p>{}</p>\\n'.format(current_time))\n",
    "        \n",
    "        txt_file.write(\"path_to_model: {}\\n\\n\".format(path_to_model))\n",
    "        html_file.write(\"<p>path_to_model: {}</p>\\n\".format(path_to_model))\n",
    "        \n",
    "        txt_file.write(\"parameters:\\n\")\n",
    "        html_file.write(\"<p>parameters:\\n<ul>\\n\")\n",
    "        for p in parameters:\n",
    "            txt_file.write(\"    {}: {}\\n\".format(p, parameters[p]))\n",
    "            html_file.write(\"<li>{}: {}\\n</li>\\n\".format(p, parameters[p]))\n",
    "        txt_file.write(\"\\n=========\\n\\n\")\n",
    "        html_file.write(\"</ul>\\n</p>\\n\")\n",
    "        \n",
    "        html_file.write(\"<ul>\")\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            html_file.write('<li><a href=\"#prompt{num}\">Prompt {num} - {p}</a></li>\\n'.format(num = i + 1, p = prompt))\n",
    "        html_file.write(\"</ul>\")\n",
    "        \n",
    "        prompt_count = 0\n",
    "        test_count = 1\n",
    "        for prompt in prompts:\n",
    "            if adjust_tabs:\n",
    "                prompt = prompt.replace('\\n', '\\t')\n",
    "            prompt_count += 1\n",
    "            print(\"running prompt {}: {}\".format(prompt_count, prompt))\n",
    "            \n",
    "            prompt_counter_text = \"prompt {}:\\n\".format(prompt_count)\n",
    "            prompt_text = \"prompt:\\n{}\\n\\n\\n\".format(prompt)\n",
    "            txt_file.write(prompt_counter_text)\n",
    "            txt_file.write(prompt_text)\n",
    "            html_file.write('<h3 id=\"prompt{}\">{}</h3>'.format(prompt_count, prompt_counter_text))\n",
    "            html_file.write(\"<p>{}<br>\".format(prompt_text))\n",
    "            \n",
    "            output = generate(prompt)\n",
    "            for setting in output:\n",
    "                s = tokenizer.decode(setting)\n",
    "                if adjust_tabs:\n",
    "                    s = s.replace('\\t', '\\n')\n",
    "                txt_file.write(s + \"\\n---\\n\")\n",
    "                html_file.write(\"\\nTest: {}\\n\".format(test_count))\n",
    "                html_file.write(html_abc_prefix)\n",
    "                html_file.write(\"X: {}\\n\".format(test_count))\n",
    "                html_file.write(s.replace(\" \", \"\") + \"\\n\\n\")\n",
    "                html_file.write(html_abc_postfix)\n",
    "                \n",
    "                test_count += 1\n",
    "            \n",
    "            html_file.write(\"</p>\")\n",
    "            txt_file.write(\"\\n---------\\n\\n\")\n",
    "            \n",
    "        \n",
    "        html_file.write(html_footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running tests on model at ./2021-07-23.3/results/checkpoint\n",
      "saving to test_results/2021-07-23t14:01:25.txt and test_results/2021-07-23t14:01:25.html\n",
      "running prompt 1: R: reel\tM: 4/4\tK: Edor\t|: E2 B E d E B E |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 2: R: jig\tM: 6/8\tK: Gmaj\t|: G3 G A B |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 3: R: polka\tM: 2/4\tK: Dmaj\td d B/ c/ d/ B/ |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 4: R: hornpipe\tM: 4/4\tK: Edor\t|: B,2 | E D E F G F G A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 5: R: waltz\tM: 3/4\tK: Gmaj\tB2 B A B d |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 6: R: slip jig\tM: 9/8\tK: Emin\t|: B2 E G2 E F3 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 7: R: jig\tM: 6/8\tK: Dmix\tf e d c A G |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 8: R: reel\tM: 4/4\tK: Dmin\tA,2 D A, F A, D A, |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 9: R: jig\tM: 6/8\tK: Adow\t|: a3 b a g |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 10: R: reel\tM: 4/4\tK: Dmaj\tA |: F A (3 A A A B A F A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 11: R: jig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 12: R: reel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 13: R: polka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 14: R: waltz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 15: R: hornpipe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 16: R: slip jig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 17: M: 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 18: M: 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 19: M: 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 20: M: 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 21: M: 9/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 22: G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 23: e\n"
     ]
    }
   ],
   "source": [
    "test_suite(adjust_tabs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate('G A B A d d |')\n",
    "for x in output:\n",
    "    print(tokenizer.decode(x), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running tests on model at ./2021-07-20.1/results/checkpoint-21610\n",
      "saving to test_results/2021-07-23t13:52:01.txt and test_results/2021-07-23t13:52:01.html\n",
      "running prompt 1: R: reel\tM: 4/4\tK: Edor\t|: E2 B E d E B E |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running prompt 2: R: jig\tM: 6/8\tK: Gmaj\t|: G3 G A B |\n"
     ]
    }
   ],
   "source": [
    "test_suite(prompts = two_prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
