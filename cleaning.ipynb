{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "raw_tunes = pd.read_json(\"tunes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial length of tunes: 39154\n",
      "drop tunes with lyrics: 39121\n",
      "drop tunes with rests: 35137\n",
      "drop tunes with multiple voices: 34899\n",
      "drop tunes with expression markings, codas etc.: 34813\n",
      "drop tunes with dal segno, coda, fermata: 34617\n",
      "drop tunes with double stops: 33297\n",
      "drop tunes with third and fourth endings: 33293\n",
      "drop tunes with notes lower than G,: 33252\n",
      "drop tunes with notes higher than d': 33141\n",
      "drop tunes with capital letters and apostrophes; lowercase letters and commas: 33075\n",
      "drop tunes with key changes: 32382\n"
     ]
    }
   ],
   "source": [
    "# create new dataframe for cleaning tunes\n",
    "tunes = raw_tunes.copy(deep=True)\n",
    "\n",
    "print('initial length of tunes:', len(tunes))\n",
    "\n",
    "# remove line breaks\n",
    "tunes['abc'] = tunes['abc'].str.replace('\\n', '', regex=True)\n",
    "tunes['abc'] = tunes['abc'].str.replace('\\r', '', regex=True)\n",
    "\n",
    "# remove spaces\n",
    "tunes['abc'] = tunes['abc'].str.replace(' ', '', regex=True)\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('w:')]\n",
    "print('drop tunes with lyrics:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('z')]\n",
    "print('drop tunes with rests:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('[vV]', regex=True)]\n",
    "print('drop tunes with multiple voices:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('!')]\n",
    "print('drop tunes with expression markings, codas etc.:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('[SOH]', regex=True)]\n",
    "print('drop tunes with dal segno, coda, fermata:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('\\[.{2,5}\\]', regex=True)]\n",
    "print('drop tunes with double stops:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('\\[3', regex=True)]\n",
    "tunes = tunes[~tunes.abc.str.contains('\\[4', regex=True)]\n",
    "print('drop tunes with third and fourth endings:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('[C-F],', regex=True)]\n",
    "tunes = tunes[~tunes.abc.str.contains('[A-G],,', regex=True)]\n",
    "print('drop tunes with notes lower than G,:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('[efgab]\\'', regex=True)]\n",
    "tunes = tunes[~tunes.abc.str.contains('[a-g]\\'\\'', regex=True)]\n",
    "print('drop tunes with notes higher than d\\':', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('[A-G]\\'', regex=True)]\n",
    "tunes = tunes[~tunes.abc.str.contains('[a-g],', regex=True)]\n",
    "print('drop tunes with capital letters and apostrophes; lowercase letters and commas:', len(tunes))\n",
    "\n",
    "tunes = tunes[~tunes.abc.str.contains('K', regex=True)]\n",
    "print('drop tunes with key changes:', len(tunes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop tunes with mismatched quotation marks: 32380\n",
      "drop tunes with mismatched curly braces: 32373\n"
     ]
    }
   ],
   "source": [
    "### clean abc\n",
    "\n",
    "# remove up- and down-bows\n",
    "tunes['abc'] = tunes['abc'].str.replace('u', '', regex=True)\n",
    "tunes['abc'] = tunes['abc'].str.replace('v', '', regex=True)\n",
    "\n",
    "# remove chord symbols\n",
    "tunes['abc'] = tunes['abc'].str.replace('\".*?\"', '', regex=True)\n",
    "tunes = tunes[~tunes.abc.str.contains('\"', regex=True)]\n",
    "print('drop tunes with mismatched quotation marks:', len(tunes))\n",
    "\n",
    "# remove slurs, but protect triplet markings\n",
    "tunes['abc'] = tunes['abc'].str.replace('\\(3', 'TRIPLET', regex=True)\n",
    "tunes['abc'] = tunes['abc'].str.replace('\\(', '', regex=True)\n",
    "tunes['abc'] = tunes['abc'].str.replace('TRIPLET', '(3', regex=True)\n",
    "tunes['abc'] = tunes['abc'].str.replace('\\)', '', regex=True)\n",
    "\n",
    "\n",
    "## remove ornaments\n",
    "# remove turns, trills, accents, mordents, slides, rolls\n",
    "tunes['abc'] = tunes['abc'].str.replace('[~TLMPJR]', '', regex=True)\n",
    "\n",
    "# remove staccato\n",
    "tunes['abc'] = tunes['abc'].str.replace('.', '', regex=False)\n",
    "\n",
    "# remove grace notes\n",
    "tunes['abc'] = tunes['abc'].str.replace('\\{.*?\\}', '', regex=True)\n",
    "tunes = tunes[~tunes.abc.str.contains('\\}', regex=True)] # apparently, only unmatched closing braces exist in the dataset, not unmatched open braces\n",
    "print('drop tunes with mismatched curly braces:', len(tunes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(setting_id: int):\n",
    "    print(\"raw:\\n\", raw_tunes.loc[raw_tunes['setting_id'] == setting_id]['abc'])\n",
    "    print(\"clean:\\n\", tunes.loc[tunes['setting_id'] == setting_id]['abc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunes.loc[tunes['abc'].str.contains('/2', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tunes.sample(n=10)['abc'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom tokens for tokenization - in order, such that larger tokens are caught first (hopefully)\n",
    "\n",
    "accidentals = ['_', '=', '^', '']\n",
    "notes = ['G,', 'A,', 'B,', 'C', 'D', 'E', 'F', 'G', 'A', 'B', \"c'\", \"d'\", 'c', 'd', 'e', 'f', 'g', 'a', 'b']\n",
    "durations = ['/8', '/4', '/2', '/', '3/2', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '']\n",
    "note_combs = [a + n + d for a in accidentals for n in notes for d in durations]\n",
    "\n",
    "# barlines and repeats\n",
    "barlines = [':||:', ':|:', '::', '|:', ':|', '[|', '|]', '[1', '[2', '|', '1', '2']\n",
    "tuplets = ['(3']\n",
    "duration_modifiers = ['>', '<']\n",
    "ties = ['-']\n",
    "\n",
    "custom_tokens = barlines + tuplets + duration_modifiers + ties + note_combs\n",
    "# NB - make sure to also add mode, meter values!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_set = set(custom_tokens)\n",
    "\n",
    "def tokenize(notes):\n",
    "    notes = notes\n",
    "    tokens = []\n",
    "    start = 0\n",
    "    #stop = 0\n",
    "    while start < len(notes):\n",
    "        found_token = False\n",
    "        for i in range(4, 0, -1):\n",
    "            stop = start + i\n",
    "            if notes[start:stop] in token_set:\n",
    "                tokens.append(notes[start:stop])\n",
    "                start = stop\n",
    "                found_token = True\n",
    "                break\n",
    "        if not found_token:\n",
    "            #print('error found')\n",
    "            return ' '.join(tokens) + ' tokenization error: ' + notes[start:]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunes['tokenized'] = tunes['abc'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = tunes[tunes.tokenized.str.contains('error', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tune_id', 'setting_id', 'name', 'type', 'meter', 'mode', 'abc', 'date',\n",
       "       'username', 'tokenized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunes['combined'] = tunes.apply(lambda x: f\"R: {x['type']}\\tM: {x['meter']}\\tK: {x['mode']}\\t{x['tokenized']}\\t\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = tunes[~tunes.tokenized.str.contains('error', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: polka\tM: 2/4\tK: Gmajor\t|: d > g f e | d B A G | E/ F/ G E/ F/ G | B A G F | d > g f e | d B A G | E/ F/ G E/ F/ G | B A G2 :||: e > f g a | b a g f | e/ f/ g e/ f/ g | d/ c/ B/ A/ B A | e > f g a | b a g f | e/ f/ g e/ f/ g | a g g2 :|\t\n"
     ]
    }
   ],
   "source": [
    "print(tunes['combined'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tune_id', 'setting_id', 'name', 'type', 'meter', 'mode', 'abc', 'date',\n",
       "       'username', 'tokenized', 'combined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda x: f\"R:{x['type']}\\n M:{x['meter']}\\n K:{x['mode']}\\n {x['abc']}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['combined'].to_csv(path_or_buf='2021_07_20_tokenized_tunes.txt', sep = '.', index=False, header=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should feed the tunes into the model in the following format:\n",
    "\n",
    "\"\"\"\n",
    "X: <setting_id>\n",
    "R: <type>\n",
    "M: <meter>\n",
    "K: <mode>\n",
    "<abc>\n",
    "/n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
